---
layout: post
title:  "Revision notes: 70-762 Developing SQL Databases"
date:   2018-03-13 21:45:09 +0100
categories: SQLServer 70-762 MicrosoftExam
---

# 70-762 Developing SQL Databases 

_These are my notes taken while reading through the Exam Ref 70-762 Developing SQL Databases by [Louis Davidson][@drsql] and [Stacia Varga][@_StaciaV_].  They were typed up on my phone while on a train, and cover whatever I felt worth making a note of.  With that in mind, perhaps they'll be of use to you._

## Part 1 - Design and Implement Databases
### Schema


Masking columns (can only see data if you have UNMASK - dbo user does have it by default):
```sql
-- At table creation
CREATE TABLE t
(
    colname NVARCHAR(50)
    -- Replaces all but a few chars with X's
    -- Note MASKED with before [NOT] NULL
    MASKED WITH (FUNCTION = 'email()') NULL
    CONSTRAINT constraintname DEFAULT ('abc@123.co.uk')
);

-- After creation
ALTER TABLE t ALTER COLUMN colname ADD MASKED WITH ...
```
Replacement functions:
```sql
-- Text replacement
FUNCTION = 'partial(a,b,c)'
--a - no of start chars
--c - end chars
--b - middle string 
 -- direct replacement with
FUNCTION = 'partial(0,"unknown",0)'
--Note that ABC -> 4,"******",4  -> ABC******ABC

-- Datatype default, not column default
FUNCTION = 'default()'

-- Number in range a to b
FUNCTION = 'random(a,b)' 
```
### Indexes
Regular index is B-Tree rowstore

Scan index, seek specific rows within

Clustered - actual data stored at leaf nodes

Non clustered index - heap - non sequential 8K pages of data.

NCI on CI table - leaves are clustered index keys.  In heap table leaves are  pointers to physical structure where data lives.  In CCSI table leaf data is position of CS index

1 key col means simple index else composite index.  Index sorted in col order - chose most selective first (i.e. most unique values)

Size of key limited to 900/1700 for CI/NCI. Smaller keys allow fewer levels. Fewer levels fewer reads. Pages hold 8060 bytes

Clustered index key (clustering key) size important as copied in all NCIs.  Changing CK causes changes in all NCIs. If not unique, 4 byte unique identifier added. Best value is increasing value - inserts in middle of sequence cause page splits. Usually PK best choice as used for joins, but could be on FK if commonly selecting children. Can also speed up large data loads if chosen sensibly.

Unique Identifier (GUID 16byte, generated with `NewId()` or `NewSequencialId()`) bad for indexing as not created in ordered manner but can be. sequential id ordered only between reboots and doesn't stop people adding non-ordered ones

NCIs don't always help as bookmark operator has cost itself

Index PK/unique/FK during design:
PK/u automatic
Can index deterministic computer columns
Check if col indexable with `columnproperty(object_id,name,'IsIndexable')` from system.columns

During development and live:
Might need indexes on common search paths, join cols and sorts

Check logical read statistics (physical reads mean need more RAM)
Large no mean index might be required as many rows are read for search

Nested loops good for joining small set to large
Hash match good for two large unordered setd
Merge join better if large sets are sorted

Can specify order of index cols. In composite index partial-matches of sort order will deliver partial benefits but will force sorting.(remember order of columns in index matters)

Included columns can help deal with cost of bookmark lookup over  queries with many rows and few columns. Never used to help seek. Needs to include all required columns to be useful - covering index. Slow down insets so maybe bad for oltp but could be good for reporting. Exam best answer often includes columns specific to query

Query plan can show that FK indexes are missing
Left semi join hash match suggests subquery rather than `JOIN` in `FROM`

Can't necessarily predict what indexes are used due to bookmark lookup -need to look at actual query plan

## Views
Partitioned views - based on union all operator. Used for combining  similar tables from different servers.
Partitioning cols must include PK.
Need to add constraints on PKS so they don't clash, eg sequence or `CONSTRAINT chkpk CHECK (pkcol BETWEEN a and b)`. Can't use identity or default on partitioning col
Source tables don't have to have same shape.
(Between is inclusive)
Requires PK predicates to query properly - will query correct servers, otherwise has to look at all even if not necessary.

### Indexed views
have clustered key - materialised view. Need to use `NOEXPAND` table hint in std edition.
Recalculates for every modification of underlying data - faster than triggers but can cause locking conflicts.
Enterprise can even use aggregates  even if view not actually referenced.(can't use select*, top, distinct, set operators, subquerys, ctes, references to other views, outer joins, recusive joins to same table, data outside database or non-deterministic, can't aggregate cols that could return null, not schema finding, count_big rather than count)

Good for reporting systems where data modification not common.

## Columnstore 
Data stored per col rather than per row, in groups of up to 1.04MRows, broken down into column segments. Segment order and Row order within row segment consistent but not logical.

Only reads the columns it cares about

Not ordered, so not good for row seeks

Doesn't support 
* (N)Varchar)MAX (clustered only)
* Row version
* Sql_variant
* cLr types (heirarchyid and spatial types)
* XML
* (N)text and image (deprecated)

SQL server 2016 CSIs can be applied to OLTP dbs for real time analytics

Segments vary in size because of compression. Can be applied at row group level or even higher rather than just page compression. Compression by replacing duplicate values by small lookup code.

Segments include hints for QP about what the column contains, e.g. min, max value

Deltastore used for new rows. Heap structure. Accumulates rows until full then thru get compressed and moved into new row group. 

`DELETE` marks rows as ignored
`UPDATE` is delete then insert.

tuple mover manages index maintenance and moving of data into from Delta store into row groups.

### Clustered or Non-Clustered?
CCS used for storage of actual data. In NC case adds additional cs index on top of existing clustered structure.

CCS recommended for Dimensional DWs

NCCS preferred for analytics on OLTP. Can perform better when multiple NCBTIs are required

NCCS doesn't compress base table data.
Can make more sensible decisions on included columns - only keys and measures.

### Use
Ideal when working on large batches of data involving most rows. Need many rows for them to be effective. 

Good in DW scenarios. Minimal changes to historic data. Can reduce table size by 90% if compresses well.

If QP uses nested loops, probably won't be so effective.

CCSIs cause LOB reads (binary object) as segments are stored as large varbinary

Column stores also trigger batch execution mode - work on groups of up to 900 rows simultaneously.

For OLTP systems, consider the query load - one specific report executed repeatedly is use case for NCBT with included columns. AdHoc reporting or cases where multiple NCBT  indexes are used might be a good use case for NCCS (again only include analytically valuable columns)

### Optimisation
Data modification a multi-step process due to indexes. All needs to be done in same transaction. Slow. 

Can set `WITH (COMPRESSION_DELAY = X)` (minutes) to set minimum time for data to stay in delta store. Ensures modification happens in delta store rather than compressed row group.

Add filter clause to target colder data (less likely to change). Alternatively use columns that determine hot/cold as part of clustering key.

### 2016 Vs previous
* 2012 Read only (required drop and recreate to modify data)
* 2014 Read write but don't work with row store indexes.(could still be more efficient to drop and recreate index)
* Now can have complementary rowstore indexes 

Add complementary indexes anywhere you want to access rows one at a time e.g. where clause predicates

### Maintenance
Tuple Mover does some reorganization in BG
```sql
ALTER INDEX idxname ON tablename [REORGANIZE/REBUILD]
```

`REORGANIZE` kicks off the tuple mover immediately. Online operation

`REBUILD` creates entirely new index. Clean and well compressed. Offline operation.

Nightly loads well suited to rebuild.

### Loading data
Bulk load with `INSERT... SELECT...FROM... WITH (TABLOCK)`. 

Allows parallel loading. Creates multiple Delta stores, depending on number of processors.  Bulk inserts of more than 102,400 rows go straight to row group (might need OPTION (MAXDOP = 1) to prevent parallelism)

Check state of Delta stores with `sys.dm_db_column_store_row_group_physical_stats`

Force tuple mover to compress data with `REORGANIZE WITH (COMPRESS_ALL_ROW_GROUPS = ON)`.

Non-bulk operations quickly fragment the index and cause slowdown. If the number of rows changed is small the tuple mover might take a long time to accommodate the changes so a `REBUILD`/`REORGANIZE` might be required.

[@drsql]: https://twitter.com/drsql
[@_StaciaV_]: https://twitter.com/_StaciaV_